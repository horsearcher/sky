Step to run the demo locally, test only on Windows 10.
1. Download both zip files, to extract into same folder.
   Make sure all dlls in same folder with sapp.exe .
   
3. Dowload any GGUF AI model to run locally.
   Put the download model in "models" folder,
   or use server start in menu, then upload to server's "models" folder.
   
   As demo, default use tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf from: https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF
   dowload link:  https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/blob/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
   
5. Then u can run the model locally, or remotely using sapp.exe .
   While server and client functions not fully tested, may not work properly.
